{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run fullmerge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('trainFull.csv', index = False)\n",
    "test.to_csv('testFull.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "320\n",
      "28\n",
      "Append good: True\n"
     ]
    }
   ],
   "source": [
    "what = train.append(test, ignore_index=True)\n",
    "len(what.columns)\n",
    "print len(test.columns)\n",
    "print len(train.columns)\n",
    "\n",
    "counter = len(train.columns)- len(test.columns)\n",
    "for i in test.columns:\n",
    "    if i not in train.columns:\n",
    "        counter += 1\n",
    "        \n",
    "print counter\n",
    "print 'Append good:', counter+len(test.columns) == len(what.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.iloc[:,0])+len(test.iloc[:,0])==len(what.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60448"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(what.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pd.notnull(what.loc[len(train.iloc[:,0]):,'cost']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "what.to_csv('traintest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nall_files = {}\\nfor afile in allfiles:\\n    key = afile.split('\\\\')[-1].split('.')[0]\\n    all_files[key] = pd.read_csv(afile, header = 0)\\nall_files['train_set'] = pd.read_csv('../competition_data/train_set.csv', header = 0, parse_dates = ['quote_date'])\\nall_files['test_set'] = pd.read_csv('../competition_data/test_set.csv', header = 0, parse_dates = ['quote_date'])\\n\\ntrain[all_files['bill_of_materials'].columns]\\ndropcol = ['component_id_7','quantity_7','component_id_8','quantity_8']\\ntest[all_files['bill_of_materials'].drop(dropcol, axis = 1).columns]\\n\\n\\n\\nweightlook = train.columns[train.columns.str.contains('weight')]\\nweightlookTest = train.columns[train.columns.str.contains('weight')]\\ntrain[weightlook]\\ntest[weightlookTest]\\n\\ntrain[['year','month','day']]\\ntest[['year','month','day']]\\n\\n\\ntrain[['end_a','end_x']]\\ntest[['end_a','end_x']]\\n\\nendformtype = train.columns[train.columns.str.contains('end_form')]\\nendformtypeTest = test.columns[test.columns.str.contains('end_form')]\\ntrain[endformtype]\\ntest[endformtypeTest]\\n\\n\\ncontype = train.columns[train.columns.str.contains('conn')]\\ncontypeTest = test.columns[test.columns.str.contains('conn')]\\ntrain[contype]\\ntest[contypeTest]\\n\\n\\ncomptype = train.columns[train.columns.str.contains('component_type')]\\ncomptypeTest = test.columns[test.columns.str.contains('component_type')]\\ntrain[comptype]\\ntest[comptypeTest]\\n\\n\\nrestfile = []\\nfor x in rest:\\n    restfile += [os.path.join('..','competition_data',x)]\\nrest_files = {}\\nfor r in restfile:\\n    key = r.split('\\\\')[-1].split('.')[0]\\n    rest_files[key] = pd.read_csv(r ,header=0)\\ntrain[list(rest_files['specs'].columns)]\\ntest[list(rest_files['specs'].columns)]\\n\\n\\n\\ncomponName = train.columns[train.columns.str.contains('component_id')]\\ncomponNameTest = test.columns[test.columns.str.contains('component_id')]\\ntrain[componName]\\ntest[componName]\\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all_files = {}\n",
    "for afile in allfiles:\n",
    "    key = afile.split('\\\\')[-1].split('.')[0]\n",
    "    all_files[key] = pd.read_csv(afile, header = 0)\n",
    "all_files['train_set'] = pd.read_csv('../competition_data/train_set.csv', header = 0, parse_dates = ['quote_date'])\n",
    "all_files['test_set'] = pd.read_csv('../competition_data/test_set.csv', header = 0, parse_dates = ['quote_date'])\n",
    "\n",
    "train[all_files['bill_of_materials'].columns]\n",
    "dropcol = ['component_id_7','quantity_7','component_id_8','quantity_8']\n",
    "test[all_files['bill_of_materials'].drop(dropcol, axis = 1).columns]\n",
    "\n",
    "\n",
    "\n",
    "train[all_files['tube'].columns]\n",
    "test[all_files['tube'].columns]\n",
    "\n",
    "\n",
    "\n",
    "weightlook = train.columns[train.columns.str.contains('weight')]\n",
    "weightlookTest = train.columns[train.columns.str.contains('weight')]\n",
    "train[weightlook]\n",
    "test[weightlookTest]\n",
    "\n",
    "\n",
    "train[['year','month','day']]\n",
    "test[['year','month','day']]\n",
    "\n",
    "\n",
    "train[['end_a','end_x']]\n",
    "test[['end_a','end_x']]\n",
    "\n",
    "endformtype = train.columns[train.columns.str.contains('end_form')]\n",
    "endformtypeTest = test.columns[test.columns.str.contains('end_form')]\n",
    "train[endformtype]\n",
    "test[endformtypeTest]\n",
    "\n",
    "\n",
    "contype = train.columns[train.columns.str.contains('conn')]\n",
    "contypeTest = test.columns[test.columns.str.contains('conn')]\n",
    "train[contype]\n",
    "test[contypeTest]\n",
    "\n",
    "\n",
    "comptype = train.columns[train.columns.str.contains('component_type')]\n",
    "comptypeTest = test.columns[test.columns.str.contains('component_type')]\n",
    "train[comptype]\n",
    "test[comptypeTest]\n",
    "\n",
    "\n",
    "restfile = []\n",
    "for x in rest:\n",
    "    restfile += [os.path.join('..','competition_data',x)]\n",
    "rest_files = {}\n",
    "for r in restfile:\n",
    "    key = r.split('\\\\')[-1].split('.')[0]\n",
    "    rest_files[key] = pd.read_csv(r ,header=0)\n",
    "train[list(rest_files['specs'].columns)]\n",
    "test[list(rest_files['specs'].columns)]\n",
    "\n",
    "\n",
    "\n",
    "componName = train.columns[train.columns.str.contains('component_id')]\n",
    "componNameTest = test.columns[test.columns.str.contains('component_id')]\n",
    "train[componName]\n",
    "test[componName]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.to_csv('trainSub.csv', index = False)\n",
    "#test.to_csv('testSub.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
